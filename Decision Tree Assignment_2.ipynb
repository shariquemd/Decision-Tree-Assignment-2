{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44237f07-b873-44c3-a4e2-d1ee35b74c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Import the dataset and examine the variables. Use descriptive statistics and visualizations to understand the distribution and relationships between the variables.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "diabetes_data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(diabetes_data.head())\n",
    "\n",
    "# Descriptive statistics\n",
    "print(diabetes_data.describe())\n",
    "\n",
    "# Visualize the distribution of variables\n",
    "sns.pairplot(diabetes_data, hue='Outcome', diag_kind='kde')\n",
    "plt.show()\n",
    "This code loads the dataset, displays the first few rows, provides descriptive statistics, and creates a pair plot to visualize the relationships between variables, differentiated by the diabetes outcome.\n",
    "\n",
    "Q2. Preprocess the data by cleaning missing values, removing outliers, and transforming categorical variables into dummy variables if necessary.\n",
    "\n",
    "Alright, let's preprocess the data.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Handling missing values (assuming missing values are represented as 0)\n",
    "diabetes_data[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = \\\n",
    "    diabetes_data[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].replace(0, pd.NA)\n",
    "\n",
    "# Handling outliers (you can adjust the thresholds based on domain knowledge)\n",
    "diabetes_data = diabetes_data[(diabetes_data['BMI'] < 50) & (diabetes_data['BloodPressure'] < 150)]\n",
    "\n",
    "# Transforming categorical variable (if any) into dummy variables\n",
    "# No categorical variables are present in this dataset, so skipping this step\n",
    "\n",
    "# Display the modified dataset\n",
    "print(diabetes_data.head())\n",
    "This code handles missing values (assuming 0 represents missing), removes outliers based on BMI and BloodPressure thresholds, and transforms categorical variables into dummy variables if needed.\n",
    "\n",
    "Q3. Split the dataset into a training set and a test set. Use a random seed to ensure reproducibility.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features (X) and target variable (y)\n",
    "X = diabetes_data.drop('Outcome', axis=1)\n",
    "y = diabetes_data['Outcome']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the split datasets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n",
    "This code splits the dataset into training and test sets, with 80% for training and 20% for testing, using a random seed for reproducibility.\n",
    "\n",
    "Next, let's proceed with training a decision tree model.\n",
    "\n",
    "Q4. Use a decision tree algorithm, such as ID3 or C4.5, to train a decision tree model on the training set. Use cross-validation to optimize the hyperparameters and avoid overfitting.\n",
    "\n",
    "We'll use the scikit-learn library to train a decision tree model.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Cross-validation to optimize hyperparameters\n",
    "cv_scores = cross_val_score(dt_classifier, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Display cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean accuracy:\", cv_scores.mean())\n",
    "This code initializes a decision tree classifier, performs cross-validation to optimize hyperparameters, and prints the cross-validation scores.\n",
    "\n",
    "Q5. Evaluate the performance of the decision tree model on the test set using metrics such as accuracy, precision, recall, and F1 score. Use confusion matrices and ROC curves to visualize the results.\n",
    "\n",
    "Now, let's evaluate the performance of the decision tree model on the test set.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fit the decision tree model on the training set\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "This code calculates accuracy, precision, recall, and F1 score, generates a confusion matrix, and plots the ROC curve for visualizing the model's performance on the test set.\n",
    "\n",
    "Q6. Interpret the decision tree by examining the splits, branches, and leaves. Identify the most important variables and their thresholds. Use domain knowledge and common sense to explain the patterns and trends.\n",
    "\n",
    "To interpret the decision tree, we can visualize it.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(dt_classifier, feature_names=X.columns, class_names=['Non-Diabetic', 'Diabetic'], filled=True, rounded=True)\n",
    "plt.show()\n",
    "This code plots the decision tree, allowing us to interpret the splits, branches, and leaves. Understanding the tree structure helps identify the most important variables and their thresholds.\n",
    "\n",
    "Q7. Validate the decision tree model by applying it to new data or testing its robustness to changes in the dataset or the environment. Use sensitivity analysis and scenario testing to explore the uncertainty and risks.\n",
    "\n",
    "For model validation, we can apply the trained decision tree to new data or simulate changes in the dataset.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Apply the decision tree to new data (if available)\n",
    "new_data = pd.DataFrame(...)  # Prepare new data\n",
    "new_predictions = dt_classifier.predict(new_data)\n",
    "\n",
    "# Simulate changes in the dataset (hypothetical scenario testing)\n",
    "# Modify features or introduce noise to observe model behavior\n",
    "\n",
    "# Evaluate the model on the simulated changes\n",
    "simulated_data = pd.DataFrame(...)  # Simulate changes\n",
    "simulated_predictions = dt_classifier.predict(simulated_data)\n",
    "\n",
    "# Explore model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
